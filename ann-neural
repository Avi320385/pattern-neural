import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = 'pattern2.csv'
df = pd.read_csv(file_path)

# Convert 'Deaths' column to binary classification
df['Deaths_binary'] = (df['Deaths'] > 0).astype(int)

# Select features and target
selected_features = ['population', 'Cases', 'Deaths']
X = df[selected_features]
y = df['Deaths_binary']  # Target column for Deaths

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data into training and testing sets (80:20)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Define ANN model
ann_model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train and evaluate the ANN model
ann_history = ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)

# Compute predictions
y_pred_ann = (ann_model.predict(X_test) > 0.5).astype("int32")

# Print Classification Report for ANN
print("Classification Report for ANN:\n", classification_report(y_test, y_pred_ann))

# Plot Accuracy and Loss for ANN
plt.figure(figsize=(14, 12))

# Accuracy Plot
plt.subplot(2, 2, 1)
plt.plot(ann_history.history['accuracy'], label='Train Accuracy')
plt.plot(ann_history.history['val_accuracy'], label='Validation Accuracy')
plt.title('ANN Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(2, 2, 2)
plt.plot(ann_history.history['loss'], label='Train Loss')
plt.plot(ann_history.history['val_loss'], label='Validation Loss')
plt.title('ANN Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

# Precision, Recall, F1-Score Plot
epochs = range(1, len(ann_history.history['accuracy']) + 1)
precision = []
recall = []
f1_score = []
support = []

for epoch in epochs:
    # Evaluate the model at the end of each epoch
    y_pred = (ann_model.predict(X_test) > 0.5).astype("int32")
    precision_epoch, recall_epoch, f1_score_epoch, support_epoch = precision_recall_fscore_support(y_test, y_pred, average='binary')
    precision.append(precision_epoch)
    recall.append(recall_epoch)
    f1_score.append(f1_score_epoch)
    support.append(support_epoch)

plt.subplot(2, 2, 3)
plt.plot(epochs, precision, label='Precision')
plt.plot(epochs, recall, label='Recall')
plt.plot(epochs, f1_score, label='F1-Score')
plt.title('Precision, Recall, F1-Score')
plt.xlabel('Epochs')
plt.ylabel('Score')
plt.legend()

# Plot Confusion Matrices for Test and All Data
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Confusion Matrix for Deaths (Test Data)
cm_ann = confusion_matrix(y_test, y_pred_ann)
sns.heatmap(cm_ann, annot=True, fmt="d", cmap="Blues", ax=axes[0])
axes[0].set_title('ANN Confusion Matrix (Deaths - Test Data)')
axes[0].set_xlabel('Predicted Label')
axes[0].set_ylabel('True Label')

# Confusion Matrix for All Data (Deaths)
y_pred_ann_all = (ann_model.predict(X_scaled) > 0.5).astype("int32")
cm_ann_all = confusion_matrix(y, y_pred_ann_all)
sns.heatmap(cm_ann_all, annot=True, fmt="d", cmap="Blues", ax=axes[1])
axes[1].set_title('ANN Confusion Matrix (Deaths - All Data)')
axes[1].set_xlabel('Predicted Label')
axes[1].set_ylabel('True Label')

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
file_path = 'pattern2.csv'
df = pd.read_csv(file_path)

# Convert 'Deaths' column to binary classification
df['Deaths_binary'] = (df['Deaths'] > 0).astype(int)

# Select features and target
selected_features = ['population', 'Cases', 'Deaths']
X = df[selected_features]
y = df['Deaths_binary']  # Target column for binary classification

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the data into training and testing sets (80:20)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Define and train the Logistic Regression model
log_reg_model = LogisticRegression()
log_reg_model.fit(X_train, y_train)

# Predict on the test set
y_pred_log_reg = log_reg_model.predict(X_test)

# Print Classification Report for Logistic Regression
print("Classification Report for Logistic Regression:\n", classification_report(y_test, y_pred_log_reg))

# Plot Confusion Matrix for Test Data
plt.figure(figsize=(8, 6))
cm_log_reg = confusion_matrix(y_test, y_pred_log_reg)
sns.heatmap(cm_log_reg, annot=True, fmt="d", cmap="Blues")
plt.title('Logistic Regression Confusion Matrix (Test Data)')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# Precision, Recall, F1-Score Plot
precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_log_reg, average='binary')
print("Precision:", precision)
print("Recall:", recall)
print("F1-Score:", f1_score)

# Plot Accuracy and Loss Curves
# Logistic Regression does not have a loss curve, so we will plot the accuracy curve based on training data
# Note: LogisticRegression does not have built-in loss history tracking like ANN, so we skip that plot

# Accuracy Curve
plt.figure(figsize=(10, 6))
plt.plot([0, 1], [0, 1], 'k--', label='No Skill')
plt.plot(log_reg_model.score(X_train, y_train), log_reg_model.score(X_test, y_test), 'o-', label='Logistic Regression')
plt.xlabel('Training Accuracy')
plt.ylabel('Testing Accuracy')
plt.title('Accuracy Curve for Logistic Regression')
plt.legend()
plt.show()
